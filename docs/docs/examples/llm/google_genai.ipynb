{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how to use the the `google-genai` Python SDK with LlamaIndex to interact with Google GenAI models.\n",
    "\n",
    "If you're opening this Notebook on colab, you will need to install LlamaIndex ðŸ¦™ and the `google-genai` Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-google-genai llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "You will need to get an API key from [Google AI Studio](https://makersuite.google.com/app/apikey). Once you have one, you can either pass it explicity to the model, or use the `GOOGLE_API_KEY` environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "You can call `complete` with a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a prominent figure in the world of computer programming, entrepreneurship, and essay writing. He's best known as:\n",
      "\n",
      "*   **Co-founder of Y Combinator:** This is arguably his biggest claim to fame. Y Combinator (YC) is a highly influential startup accelerator that has funded companies like Airbnb, Dropbox, Reddit, Stripe, and many others. Graham's insights and mentorship at YC have shaped the landscape of the tech startup world.\n",
      "\n",
      "*   **Author and Essayist:** Graham is a prolific writer, known for his insightful essays on topics ranging from technology and startups to programming, design, and even art. His essays are widely read and often spark debate within the tech community. Some popular essays include \"Hackers & Painters,\" \"Beating the Averages,\" and \"Do Things That Don't Scale.\"\n",
      "\n",
      "*   **Computer Programmer and Hacker:** Graham is a skilled programmer, particularly known for his work in Lisp. He co-founded Viaweb, a startup that created software for building online stores, which was later acquired by Yahoo! and became Yahoo! Store.\n",
      "\n",
      "*   **Venture Capitalist:** Through Y Combinator, Graham and his partners have invested in and mentored a large number of startups, playing a significant role in the venture capital ecosystem.\n",
      "\n",
      "In summary, Paul Graham is a multifaceted individual who has made significant contributions to the tech world as an entrepreneur, programmer, writer, and investor. His influence is particularly strong within the startup community.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    # api_key=\"some key\",  # uses GOOGLE_API_KEY env var by default\n",
    ")\n",
    "\n",
    "resp = llm.complete(\"Who is Paul Graham?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also call `chat` with a list of chat messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Ahoy there, matey! Gather 'round, you landlubbers, and let ol' One-Eyed Jack spin ye a yarn that'll curl yer barnacles and raise yer timbers! This ain't no tale for the faint of heart, mind ye, it's the true story of the Devil's Kiss, the most beautiful, and most cursed, ruby in all the seven seas!\n",
      "\n",
      "Now, I acquired thisâ€¦ knowledge, shall we say, back when I was a mere swab, scrubbing decks for Captain \"Rotten\" Roger Reddington. Rotten Roger, bless his scurvy-infested soul, was obsessed with finding the lost treasure of Bartholomew Blackheart, a pirate so vile, he used to floss with sharks' teeth!\n",
      "\n",
      "For years, Rotten Roger chased whispers and rumors, from the soggy jungles of Tortuga to the frozen fjords of the North. Then, one day, we landed on a forsaken isle, a place called Isle de la Llorona, or Weeping Woman's Isle, for those who can't mangle a good foreign tongue. Locals warned us the island was haunted, cursed by the spirit of a maiden who Blackheart had scorned and left to die.\n",
      "\n",
      "Rotten Roger, being about as superstitious as a sea slug, scoffed. \"Ghosts? Bah! I'll face a Kraken with a spoon before I fear a woman's tears!\" He charged into the jungle, me and the rest of the crew trailing behind like so many sea dogs.\n",
      "\n",
      "We stumbled upon a crumbling temple, covered in vines and reeking of decay. Inside, amidst the cobwebs and bat droppings, we found it! Blackheart's tomb! Rotten Roger let out a whoop that would wake the dead, and started tearing through the sarcophagus.\n",
      "\n",
      "And there it was! Resting on a cushion of faded velvet, the Devil's Kiss. A ruby so red, it looked like it held a drop of hellfire itself. It pulsed with a wicked light, hypnotizing even the most grizzled pirates.\n",
      "\n",
      "Rotten Roger grabbed the ruby, cackling like a hyena. That's when the wind started howling, and the ground began to shake. The air grew thick with the scent of brine and sorrow.\n",
      "\n",
      "Then we saw her. The Weeping Woman. A spectral figure, pale as moonlight, with tears that flowed like rivers. She let out a wail that could shatter glass, and pointed a skeletal finger at Rotten Roger.\n",
      "\n",
      "\"You dare disturb his rest?\" she shrieked. \"You shall pay the price!\"\n",
      "\n",
      "Now, most of the crew, being the cowardly lot they were, hightailed it back to the ship. But Rotten Roger, blinded by greed, stood his ground. He clutched the Devil's Kiss and roared, \"I ain't afraid of no ghost! This ruby is mine!\"\n",
      "\n",
      "That's when the curse truly began. One by one, the crew started to meet unfortunate ends. One swallowed a live lobster whole, another was struck by lightning on a clear day, and a thirdâ€¦ well, let's just say he tried to shave his beard with a cutlass and wasn't very good at it.\n",
      "\n",
      "Rotten Roger, meanwhile, became increasingly paranoid and erratic. He wouldn't sleep, he barely ate, and he started seeing the Weeping Woman everywhere he looked. He blamed the ruby, but he couldn't bring himself to let it go.\n",
      "\n",
      "Finally, in a fit of madness, he decided to bury the ruby back on the Isle de la Llorona, hoping to appease the ghost. But as he dug the hole, the Weeping Woman appeared again. She grabbed him, and with a bloodcurdling scream, pulled him into the earth!\n",
      "\n",
      "The next morning, the few remaining crew members, myself included, abandoned the island. We never spoke of the Devil's Kiss again.\n",
      "\n",
      "So, that's the tale, mateys. A cautionary one, indeed. The Devil's Kiss is still out there, buried with Rotten Roger on the Isle de la Llorona. A beautiful, cursed gem that brings nothing but misfortune. Take it from ol' One-Eyed Jack, some treasures are best left buried. Now, who's buying the next round of grog? This old pirate's throat is drier than a desert rat's sock!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"system\", content=\"You are a pirate with a colorful personality\"\n",
    "    ),\n",
    "    ChatMessage(role=\"user\", content=\"Tell me a story\"),\n",
    "]\n",
    "llm = GoogleGenAI(model=\"gemini-2.0-flash\")\n",
    "resp = llm.chat(messages)\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Support\n",
    "\n",
    "Every method supports streaming through the `stream_` prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a prominent figure in the technology and startup world. Here's a summary of who he is and why he's known:\n",
      "\n",
      "*   **Computer Programmer and Essayist:** Graham is a skilled programmer, known for his work in Lisp, and he's a prolific and influential essayist on topics ranging from programming and startups to art and philosophy.\n",
      "\n",
      "*   **Co-founder of Viaweb (later Yahoo! Store):** He co-founded Viaweb, which was one of the first companies to offer a web-based application for building and hosting online stores. Yahoo! acquired Viaweb in 1998, and it became Yahoo! Store.\n",
      "\n",
      "*   **Founder of Y Combinator (YC):** He's most famous for co-founding Y Combinator (YC) in 2005. YC is a highly successful startup accelerator that provides seed funding, mentorship, and network connections to early-stage startups. It has funded many well-known companies, including Airbnb, Dropbox, Reddit, Stripe, and many others.\n",
      "\n",
      "*   **Influential Thinker on Startups:** Through Y Combinator and his essays, Graham has profoundly shaped the way people think about startups. He's known for his practical advice, focusing on building things that people want, iterating quickly, and achieving rapid growth. His essays are widely read and discussed in the startup community.\n",
      "\n",
      "*   **Author:** He's the author of several books, including \"On Lisp,\" \"Hackers & Painters,\" and \"ANSI Common Lisp.\"\n",
      "\n",
      "In summary, Paul Graham is a successful entrepreneur, programmer, essayist, and investor who has played a significant role in shaping the modern startup ecosystem through Y Combinator and his influential writings.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "resp = llm.stream_complete(\"Who is Paul Graham?\")\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a prominent figure in the technology and startup world, best known for several key accomplishments:\n",
      "\n",
      "*   **Co-founder of Y Combinator (YC):** This is arguably his most significant achievement. Y Combinator is a highly influential startup accelerator that has funded and mentored numerous successful companies, including Airbnb, Dropbox, Reddit, Stripe, and many more. Graham's experience and insights shaped YC's unique approach to early-stage startup investing and guidance.\n",
      "\n",
      "*   **Author and Essayist:** Graham is a prolific writer, known for his thought-provoking essays on topics ranging from programming and startups to art, education, and societal trends. His essays are widely read and discussed within the tech community. Some popular essays include \"Hackers and Painters,\" \"Do Things That Don't Scale,\" and \"How to Start a Startup.\" His writing style is known for its clarity, directness, and often contrarian viewpoints.\n",
      "\n",
      "*   **Programmer and Hacker:** He has a strong background in computer science and programming. He holds a Ph.D. in computer science from Harvard.\n",
      "\n",
      "*   **Viaweb/Yahoo! Store:** Before Y Combinator, Graham co-founded Viaweb, one of the first software as a service (SaaS) companies, which provided tools for building online stores. Viaweb was later acquired by Yahoo! and became Yahoo! Store.\n",
      "\n",
      "**In summary, Paul Graham is a highly influential figure in the startup world because of his role in creating and shaping Y Combinator, his insightful essays, and his background as a programmer and entrepreneur.** He is often sought after for his advice and opinions on startups, technology, and innovation."
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"Who is Paul Graham?\"),\n",
    "]\n",
    "\n",
    "resp = llm.stream_chat(messages)\n",
    "for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async Usage\n",
    "\n",
    "Every synchronous method has an async counterpart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a prominent figure in the tech world, known for several key accomplishments:\n",
      "\n",
      "*   **Co-founder of Y Combinator:** This is arguably his most well-known role. Y Combinator (YC) is a highly influential startup accelerator that has funded and mentored companies like Airbnb, Dropbox, Stripe, Reddit, and many others. Graham's vision and approach to early-stage startup funding have significantly shaped the startup ecosystem.\n",
      "*   **Programmer and Essayist:** Before Y Combinator, Graham was a respected programmer. He co-founded Viaweb, an early e-commerce platform that was acquired by Yahoo! and became Yahoo! Store. He's also a prolific essayist, writing on topics ranging from technology, startups, programming, art, and society. His essays are known for their clear writing style, insightful observations, and sometimes contrarian viewpoints. They are widely read within the startup community.\n",
      "*   **Lisp Expert:** Graham is a strong proponent of the Lisp programming language. He wrote the book \"On Lisp\" and has advocated for its use in various applications.\n",
      "*   **Investor and Advisor:** Through Y Combinator and personally, Graham has invested in and advised numerous startups. His experience and perspective are highly sought after by entrepreneurs.\n",
      "\n",
      "In short, Paul Graham is a highly influential programmer, entrepreneur, investor, and essayist who has played a significant role in shaping the modern tech startup landscape, particularly through his work with Y Combinator."
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "resp = await llm.astream_complete(\"Who is Paul Graham?\")\n",
    "async for r in resp:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: Paul Graham is a prominent figure in the world of computer science, venture capital, and writing. Here's a breakdown of who he is and why he's significant:\n",
      "\n",
      "**Key Highlights:**\n",
      "\n",
      "*   **Computer Scientist:** He holds a Ph.D. in computer science from Harvard and is known for his work in Lisp programming. He developed Viaweb, one of the first software companies to provide an online application.\n",
      "\n",
      "*   **Entrepreneur:** He co-founded Viaweb, which was later acquired by Yahoo! and became Yahoo! Store.\n",
      "\n",
      "*   **Venture Capitalist:** He co-founded Y Combinator (YC), one of the most successful startup accelerators in the world. YC has funded companies like Airbnb, Dropbox, Stripe, Reddit, Coinbase, and many others. He stepped down from managing YC in 2014, but remains involved.\n",
      "\n",
      "*   **Essayist:** Graham is a prolific and influential essayist. He writes about a wide range of topics, including startups, technology, cities, writing, and philosophy. His essays are widely read in the tech community and beyond.\n",
      "\n",
      "*   **Influencer:** Because of his success with Y Combinator and his insightful essays, Graham is considered a major thought leader in the startup and technology world. His ideas have shaped the way many startups are built and funded.\n",
      "\n",
      "**In more detail:**\n",
      "\n",
      "*   **Education and Early Career:** Graham studied at Cornell University and Harvard University, where he earned his Ph.D. in computer science. His academic background is in artificial intelligence and Lisp programming.\n",
      "\n",
      "*   **Viaweb (Later Yahoo! Store):** He co-founded Viaweb, which provided tools for businesses to create online stores. It was a pioneer in e-commerce and one of the first SaaS (Software as a Service) companies. Yahoo! acquired Viaweb in 1998 and renamed it Yahoo! Store.\n",
      "\n",
      "*   **Y Combinator (YC):** In 2005, Graham, along with Jessica Livingston, Robert Morris, and Trevor Blackwell, founded Y Combinator. YC provides seed funding, mentorship, and networking opportunities to early-stage startups. It runs programs twice a year, investing in a large number of startups each cycle.\n",
      "\n",
      "*   **Essays:** Graham's essays are a cornerstone of his influence. They are known for their clarity, insightful observations, and contrarian viewpoints. Some of his most popular essays include \"How to Start a Startup,\" \"Do Things That Don't Scale,\" \"Cities and Ambition,\" and \"Hackers and Painters.\" These essays often offer practical advice and thought-provoking perspectives on entrepreneurship, technology, and life. They are available on his website, paulgraham.com.\n",
      "\n",
      "*   **Programming Language: Lisp:** Graham is a strong advocate for Lisp and has written extensively about its power and elegance. He believes that Lisp's features make it particularly well-suited for prototyping and exploring new ideas.\n",
      "\n",
      "In summary, Paul Graham is a multifaceted figure who has made significant contributions to computer science, entrepreneurship, and venture capital. His work with Y Combinator has helped launch numerous successful startups, and his essays have inspired and informed countless people in the tech industry and beyond.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    ChatMessage(role=\"user\", content=\"Who is Paul Graham?\"),\n",
    "]\n",
    "\n",
    "resp = await llm.achat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertex AI Support\n",
    "\n",
    "By providing the `region` and `project_id` parameters (either through environment variables or directly), you can use an Anthropic model through Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "!export GOOGLE_GENAI_USE_VERTEXAI=true\n",
    "!export GOOGLE_CLOUD_PROJECT='your-project-id'\n",
    "!export GOOGLE_CLOUD_LOCATION='us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paul Graham is a prominent figure in the tech and startup world, best known for his roles as:\n",
      "\n",
      "*   **Co-founder of Y Combinator (YC):** This is arguably his most influential role. YC is a highly successful startup accelerator that has funded companies like Airbnb, Dropbox, Stripe, Reddit, and many others. Graham's approach to funding and mentoring startups has significantly shaped the startup ecosystem.\n",
      "\n",
      "*   **Essayist and Programmer:** Before YC, Graham was a programmer and essayist. He's known for his insightful and often contrarian essays on a wide range of topics, including programming, startups, design, and societal trends. His essays are widely read and discussed in the tech community.\n",
      "\n",
      "*   **Founder of Viaweb (later Yahoo! Store):** Graham founded Viaweb, one of the first application service providers, which allowed users to build and manage online stores. It was acquired by Yahoo! in 1998 and became Yahoo! Store.\n",
      "\n",
      "In summary, Paul Graham is a highly influential figure in the startup world, known for his role in creating Y Combinator, his insightful essays, and his earlier success as a programmer and entrepreneur.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "# or set the parameters directly\n",
    "llm = GoogleGenAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    vertexai_config={\"project\": \"your-project-id\", \"location\": \"us-central1\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Modal Support\n",
    "\n",
    "Using `ChatMessage` objects, you can pass in images and text to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-09 20:36:14--  https://cdn.pixabay.com/photo/2021/12/12/20/00/play-6865967_640.jpg\n",
      "Resolving cdn.pixabay.com (cdn.pixabay.com)... 172.64.147.160, 104.18.40.96, 2606:4700:4400::6812:2860, ...\n",
      "Connecting to cdn.pixabay.com (cdn.pixabay.com)|172.64.147.160|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 71557 (70K) [binary/octet-stream]\n",
      "Saving to: â€˜image.jpgâ€™\n",
      "\n",
      "image.jpg           100%[===================>]  69.88K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2025-03-09 20:36:14 (3.08 MB/s) - â€˜image.jpgâ€™ saved [71557/71557]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://cdn.pixabay.com/photo/2021/12/12/20/00/play-6865967_640.jpg -O image.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: The image contains four wooden dice on a dark fabric surface. All the dice are showing the side with six dots.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage, TextBlock, ImageBlock\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "messages = [\n",
    "    ChatMessage(\n",
    "        role=\"user\",\n",
    "        blocks=[\n",
    "            ImageBlock(path=\"image.jpg\"),\n",
    "            TextBlock(text=\"What is in this image?\"),\n",
    "        ],\n",
    "    )\n",
    "]\n",
    "\n",
    "resp = llm.chat(messages)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Prediction\n",
    "\n",
    "LlamaIndex provides an intuitive interface for converting any Anthropic LLMs into a structured LLM through `structured_predict` - simply define the target Pydantic class (can be nested), and given a prompt, we extract out the desired object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text from text parts,check out the non text parts for full response from model.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.bridge.pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class MenuItem(BaseModel):\n",
    "    \"\"\"A menu item in a restaurant.\"\"\"\n",
    "\n",
    "    course_name: str\n",
    "    is_vegetarian: bool\n",
    "\n",
    "\n",
    "class Restaurant(BaseModel):\n",
    "    \"\"\"A restaurant with name, city, and cuisine.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    city: str\n",
    "    cuisine: str\n",
    "    menu_items: List[MenuItem]\n",
    "\n",
    "\n",
    "llm = GoogleGenAI(model=\"gemini-2.0-flash\")\n",
    "prompt_tmpl = PromptTemplate(\n",
    "    \"Generate a restaurant in a given city {city_name}\"\n",
    ")\n",
    "\n",
    "# Option 1: Use `as_structured_llm`\n",
    "restaurant_obj = (\n",
    "    llm.as_structured_llm(Restaurant)\n",
    "    .complete(prompt_tmpl.format(city_name=\"Miami\"))\n",
    "    .raw\n",
    ")\n",
    "# Option 2: Use `structured_predict`\n",
    "# restaurant_obj = llm.structured_predict(Restaurant, prompt_tmpl, city_name=\"Miami\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Mamma Mia' city='Miami' cuisine='Italian' menu_items=[MenuItem(course_name='pasta', is_vegetarian=False)]\n"
     ]
    }
   ],
   "source": [
    "print(restaurant_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured Prediction with Streaming\n",
    "\n",
    "Any LLM wrapped with `as_structured_llm` supports streaming through `stream_chat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': 'San Francisco',\n",
      " 'cuisine': 'Italian',\n",
      " 'menu_items': [{'course_name': 'pizza', 'is_vegetarian': False}],\n",
      " 'name': \"Luigi's\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43030/1885953561.py:11: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  pprint(partial_output.raw.dict())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Restaurant(name=\"Luigi's\", city='San Francisco', cuisine='Italian', menu_items=[MenuItem(course_name='pizza', is_vegetarian=False)])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.llms import ChatMessage\n",
    "from IPython.display import clear_output\n",
    "from pprint import pprint\n",
    "\n",
    "input_msg = ChatMessage.from_str(\"Generate a restaurant in San Francisco\")\n",
    "\n",
    "sllm = llm.as_structured_llm(Restaurant)\n",
    "stream_output = sllm.stream_chat([input_msg])\n",
    "for partial_output in stream_output:\n",
    "    clear_output(wait=True)\n",
    "    pprint(partial_output.raw.dict())\n",
    "    restaurant_obj = partial_output.raw\n",
    "\n",
    "restaurant_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool/Function Calling\n",
    "\n",
    "Google GenAI supports direct tool/function calling through the API. Using LlamaIndex, we can implement some core agentic tool calling patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "from datetime import datetime\n",
    "\n",
    "llm = GoogleGenAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "\n",
    "def get_current_time(timezone: str) -> dict:\n",
    "    \"\"\"Get the current time\"\"\"\n",
    "    return {\n",
    "        \"time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"timezone\": timezone,\n",
    "    }\n",
    "\n",
    "\n",
    "# uses the tool name, any type annotations, and docstring to describe the tool\n",
    "tool = FunctionTool.from_defaults(fn=get_current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simply do a single pass to call the tool and get the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': '2025-03-09 20:36:30', 'timezone': 'America/New_York'}\n"
     ]
    }
   ],
   "source": [
    "resp = llm.predict_and_call([tool], \"What is the current time in New York?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use lower-level APIs to implement an agentic tool-calling loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling get_current_time with {'timezone': 'America/New_York'}\n",
      "Tool output:  {'time': '2025-03-09 20:36:32', 'timezone': 'America/New_York'}\n",
      "Final response:  The current time in New York is 2025-03-09 20:36:32.\n"
     ]
    }
   ],
   "source": [
    "chat_history = [\n",
    "    ChatMessage(role=\"user\", content=\"What is the current time in New York?\")\n",
    "]\n",
    "tools_by_name = {t.metadata.name: t for t in [tool]}\n",
    "\n",
    "resp = llm.chat_with_tools([tool], chat_history=chat_history)\n",
    "tool_calls = llm.get_tool_calls_from_response(\n",
    "    resp, error_on_no_tool_call=False\n",
    ")\n",
    "\n",
    "if not tool_calls:\n",
    "    print(resp)\n",
    "else:\n",
    "    while tool_calls:\n",
    "        # add the LLM's response to the chat history\n",
    "        chat_history.append(resp.message)\n",
    "\n",
    "        for tool_call in tool_calls:\n",
    "            tool_name = tool_call.tool_name\n",
    "            tool_kwargs = tool_call.tool_kwargs\n",
    "\n",
    "            print(f\"Calling {tool_name} with {tool_kwargs}\")\n",
    "            tool_output = tool.call(**tool_kwargs)\n",
    "            print(\"Tool output: \", tool_output)\n",
    "            chat_history.append(\n",
    "                ChatMessage(\n",
    "                    role=\"tool\",\n",
    "                    content=str(tool_output),\n",
    "                    # most LLMs like Anthropic, OpenAI, etc. need to know the tool call id\n",
    "                    additional_kwargs={\"tool_call_id\": tool_call.tool_id},\n",
    "                )\n",
    "            )\n",
    "\n",
    "            resp = llm.chat_with_tools([tool], chat_history=chat_history)\n",
    "            tool_calls = llm.get_tool_calls_from_response(\n",
    "                resp, error_on_no_tool_call=False\n",
    "            )\n",
    "    print(\"Final response: \", resp.message.content)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "gemini.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "llama-index-XWn_XfFA-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
